{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBEgUZqaET2s/gEsYTNkE1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alzaidawi/PORTAL_code/blob/main/CNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzipping the dataset"
      ],
      "metadata": {
        "id": "705npZCq5_Vn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzNoBTaV56vj",
        "outputId": "6fe86ae1-efc5-47e9-8c90-f015e61db9d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed successfully.\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Step 1: Specify the path of the zip file\n",
        "zip_file_path = \"/content/three_pore_typs.zip\"\n",
        "\n",
        "# Step 2: Provide the directory where you want to extract the contents\n",
        "destination_folder = \"/content/extracted_files\"\n",
        "\n",
        "# Step 3: Create the destination folder if it doesn't exist\n",
        "if not os.path.exists(destination_folder):\n",
        "    os.makedirs(destination_folder)\n",
        "\n",
        "# Step 4: Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_folder)\n",
        "\n",
        "print(\"Extraction completed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Model 1.4 Only CNN"
      ],
      "metadata": {
        "id": "5rfm-OBd6JDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "# Define the learning rate scheduler\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch < 50:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)\n",
        "\n",
        "# Define the image data generator with data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./360,\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.3,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # 20% of the data will be used for validation\n",
        ")\n",
        "\n",
        "# Define the image size and batch size\n",
        "img_size = (360, 360)\n",
        "batch_size = 32\n",
        "\n",
        "# Prepare the training dataset\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/extracted_files/three_pore_typs',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Prepare the validation dataset\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    '/content/extracted_files/three_pore_typs',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Define the CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10)  # Monitor 'loss' instead of 'val_loss'\n",
        "\n",
        "# Define the learning rate scheduler callback\n",
        "lr_scheduler_callback = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "# Train the model with early stopping and learning rate scheduler\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=100, callbacks=[early_stopping, lr_scheduler_callback])\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(val_generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScfvqVQi6KGw",
        "outputId": "edc65cf7-56a4-4257-b95a-cc20165e862f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 120 images belonging to 3 classes.\n",
            "Found 30 images belonging to 3 classes.\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 56s 14s/step - loss: 5.8899 - accuracy: 0.4167 - val_loss: 4.2349 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 4.2916 - accuracy: 0.6333 - val_loss: 4.2363 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 50s 12s/step - loss: 4.2058 - accuracy: 0.5917 - val_loss: 3.7120 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 3.5227 - accuracy: 0.6083 - val_loss: 2.9781 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 50s 13s/step - loss: 3.0360 - accuracy: 0.6750 - val_loss: 2.7468 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 2.6768 - accuracy: 0.7583 - val_loss: 2.5316 - val_accuracy: 0.6333 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 2.5907 - accuracy: 0.6583 - val_loss: 2.3416 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 55s 12s/step - loss: 2.3461 - accuracy: 0.6917 - val_loss: 2.1639 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 49s 13s/step - loss: 2.2006 - accuracy: 0.7333 - val_loss: 2.0224 - val_accuracy: 0.8667 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 52s 13s/step - loss: 2.2164 - accuracy: 0.6667 - val_loss: 2.0493 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 1.9869 - accuracy: 0.8250 - val_loss: 1.8894 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 2.0699 - accuracy: 0.6917 - val_loss: 1.9249 - val_accuracy: 0.8667 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 47s 11s/step - loss: 1.9647 - accuracy: 0.7500 - val_loss: 1.8739 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 50s 12s/step - loss: 1.9382 - accuracy: 0.7500 - val_loss: 1.8745 - val_accuracy: 0.8333 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.9611 - accuracy: 0.7417 - val_loss: 1.8848 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.9320 - accuracy: 0.7333 - val_loss: 1.7976 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 59s 12s/step - loss: 1.8490 - accuracy: 0.7750 - val_loss: 1.8922 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 50s 13s/step - loss: 1.8649 - accuracy: 0.7500 - val_loss: 1.6983 - val_accuracy: 0.9667 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 1.8386 - accuracy: 0.7500 - val_loss: 1.6607 - val_accuracy: 0.8333 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 47s 12s/step - loss: 1.7702 - accuracy: 0.7667 - val_loss: 1.7740 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 50s 13s/step - loss: 1.7349 - accuracy: 0.7750 - val_loss: 1.5926 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 1.6632 - accuracy: 0.7917 - val_loss: 1.6230 - val_accuracy: 0.8667 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 1.6588 - accuracy: 0.7750 - val_loss: 1.6391 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 50s 12s/step - loss: 1.6073 - accuracy: 0.7500 - val_loss: 1.5274 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.6504 - accuracy: 0.7250 - val_loss: 1.5246 - val_accuracy: 0.8333 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 60s 16s/step - loss: 1.6140 - accuracy: 0.7667 - val_loss: 1.5440 - val_accuracy: 0.8667 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.6294 - accuracy: 0.7500 - val_loss: 1.4383 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 51s 13s/step - loss: 1.5174 - accuracy: 0.7833 - val_loss: 1.6259 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 1.4995 - accuracy: 0.7833 - val_loss: 1.3796 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 47s 11s/step - loss: 1.4897 - accuracy: 0.7583 - val_loss: 1.3564 - val_accuracy: 0.8333 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 51s 13s/step - loss: 1.5014 - accuracy: 0.8333 - val_loss: 1.4395 - val_accuracy: 0.8333 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.4106 - accuracy: 0.8417 - val_loss: 1.3223 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 1.3702 - accuracy: 0.8500 - val_loss: 1.3528 - val_accuracy: 0.8667 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 50s 12s/step - loss: 1.4135 - accuracy: 0.8167 - val_loss: 1.3367 - val_accuracy: 0.8333 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 59s 16s/step - loss: 1.3785 - accuracy: 0.7917 - val_loss: 1.3009 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.3576 - accuracy: 0.8250 - val_loss: 1.4643 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 47s 11s/step - loss: 1.4595 - accuracy: 0.7917 - val_loss: 1.4287 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 50s 12s/step - loss: 1.3487 - accuracy: 0.8333 - val_loss: 1.4198 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 49s 13s/step - loss: 1.3137 - accuracy: 0.8917 - val_loss: 1.3730 - val_accuracy: 0.8667 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 49s 13s/step - loss: 1.3129 - accuracy: 0.8583 - val_loss: 1.2306 - val_accuracy: 0.8667 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 50s 12s/step - loss: 1.3164 - accuracy: 0.8333 - val_loss: 1.2618 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.2723 - accuracy: 0.8250 - val_loss: 1.3312 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 47s 12s/step - loss: 1.2361 - accuracy: 0.8333 - val_loss: 1.1865 - val_accuracy: 0.9000 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 52s 12s/step - loss: 1.1740 - accuracy: 0.9000 - val_loss: 1.1359 - val_accuracy: 0.9667 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 1.1571 - accuracy: 0.8667 - val_loss: 1.1651 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 50s 12s/step - loss: 1.1400 - accuracy: 0.8750 - val_loss: 1.4174 - val_accuracy: 0.8333 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.1059 - accuracy: 0.9000 - val_loss: 1.2143 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 49s 13s/step - loss: 1.1809 - accuracy: 0.7750 - val_loss: 1.2458 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 49s 13s/step - loss: 1.1492 - accuracy: 0.8417 - val_loss: 1.1740 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 1.1013 - accuracy: 0.8833 - val_loss: 1.2533 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.1066 - accuracy: 0.9083 - val_loss: 1.1267 - val_accuracy: 0.8000 - lr: 9.0484e-04\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 1.1230 - accuracy: 0.8917 - val_loss: 1.0639 - val_accuracy: 0.8667 - lr: 8.1873e-04\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 1.1048 - accuracy: 0.8417 - val_loss: 1.0784 - val_accuracy: 0.9000 - lr: 7.4082e-04\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 47s 11s/step - loss: 1.0505 - accuracy: 0.8833 - val_loss: 0.9376 - val_accuracy: 0.9667 - lr: 6.7032e-04\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 49s 13s/step - loss: 1.0193 - accuracy: 0.8667 - val_loss: 1.0743 - val_accuracy: 0.8000 - lr: 6.0653e-04\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 1.0343 - accuracy: 0.8500 - val_loss: 1.0181 - val_accuracy: 0.8667 - lr: 5.4881e-04\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 50s 12s/step - loss: 0.9518 - accuracy: 0.9083 - val_loss: 0.9732 - val_accuracy: 0.8667 - lr: 4.9659e-04\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.9690 - accuracy: 0.8417 - val_loss: 0.9660 - val_accuracy: 0.9333 - lr: 4.4933e-04\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.8271 - accuracy: 0.9500 - val_loss: 0.9888 - val_accuracy: 0.8000 - lr: 4.0657e-04\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.9021 - accuracy: 0.8667 - val_loss: 0.8798 - val_accuracy: 0.9333 - lr: 3.6788e-04\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.8130 - accuracy: 0.9167 - val_loss: 0.9066 - val_accuracy: 0.8667 - lr: 3.3287e-04\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.7964 - accuracy: 0.9000 - val_loss: 0.8782 - val_accuracy: 0.8000 - lr: 3.0119e-04\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.7365 - accuracy: 0.9583 - val_loss: 0.8955 - val_accuracy: 0.9000 - lr: 2.7253e-04\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 46s 11s/step - loss: 0.7448 - accuracy: 0.9333 - val_loss: 0.8825 - val_accuracy: 0.8667 - lr: 2.4660e-04\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.8137 - accuracy: 0.9000 - val_loss: 0.7561 - val_accuracy: 0.8667 - lr: 2.2313e-04\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.7480 - accuracy: 0.8917 - val_loss: 0.6802 - val_accuracy: 0.9667 - lr: 2.0190e-04\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.7044 - accuracy: 0.9500 - val_loss: 0.6847 - val_accuracy: 0.9667 - lr: 1.8268e-04\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.7632 - accuracy: 0.9083 - val_loss: 0.6435 - val_accuracy: 0.9667 - lr: 1.6530e-04\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.7047 - accuracy: 0.9167 - val_loss: 0.7378 - val_accuracy: 0.9000 - lr: 1.4957e-04\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.7100 - accuracy: 0.9417 - val_loss: 0.8151 - val_accuracy: 0.9000 - lr: 1.3534e-04\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6843 - accuracy: 0.9333 - val_loss: 0.7217 - val_accuracy: 0.9333 - lr: 1.2246e-04\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.7096 - accuracy: 0.9417 - val_loss: 0.6520 - val_accuracy: 1.0000 - lr: 1.1080e-04\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6783 - accuracy: 0.9167 - val_loss: 0.7783 - val_accuracy: 0.8667 - lr: 1.0026e-04\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6338 - accuracy: 0.9250 - val_loss: 0.6401 - val_accuracy: 0.9667 - lr: 9.0718e-05\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 51s 13s/step - loss: 0.6465 - accuracy: 0.9333 - val_loss: 0.6668 - val_accuracy: 0.9333 - lr: 8.2085e-05\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6205 - accuracy: 0.9500 - val_loss: 0.6696 - val_accuracy: 0.9333 - lr: 7.4274e-05\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 50s 12s/step - loss: 0.7045 - accuracy: 0.9417 - val_loss: 0.7256 - val_accuracy: 0.9000 - lr: 6.7206e-05\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6494 - accuracy: 0.9250 - val_loss: 0.7076 - val_accuracy: 0.8333 - lr: 6.0810e-05\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6438 - accuracy: 0.9333 - val_loss: 0.6026 - val_accuracy: 1.0000 - lr: 5.5023e-05\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6588 - accuracy: 0.9333 - val_loss: 0.6991 - val_accuracy: 0.9000 - lr: 4.9787e-05\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.6109 - accuracy: 0.9417 - val_loss: 0.6344 - val_accuracy: 0.9333 - lr: 4.5049e-05\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6090 - accuracy: 0.9583 - val_loss: 0.6031 - val_accuracy: 0.9667 - lr: 4.0762e-05\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.6189 - accuracy: 0.9417 - val_loss: 0.6304 - val_accuracy: 0.9667 - lr: 3.6883e-05\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 50s 12s/step - loss: 0.6036 - accuracy: 0.9583 - val_loss: 0.6108 - val_accuracy: 0.9667 - lr: 3.3373e-05\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6010 - accuracy: 0.9250 - val_loss: 0.6391 - val_accuracy: 0.9667 - lr: 3.0197e-05\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6034 - accuracy: 0.9500 - val_loss: 0.6016 - val_accuracy: 0.9667 - lr: 2.7324e-05\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.6135 - accuracy: 0.9417 - val_loss: 0.5543 - val_accuracy: 0.9667 - lr: 2.4724e-05\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.5571 - accuracy: 0.9667 - val_loss: 0.5899 - val_accuracy: 0.9667 - lr: 2.2371e-05\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 50s 12s/step - loss: 0.6050 - accuracy: 0.9500 - val_loss: 0.6266 - val_accuracy: 0.9667 - lr: 2.0242e-05\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.5796 - accuracy: 0.9667 - val_loss: 0.6597 - val_accuracy: 0.9000 - lr: 1.8316e-05\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6430 - accuracy: 0.9083 - val_loss: 0.6761 - val_accuracy: 0.9000 - lr: 1.6573e-05\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.5593 - accuracy: 0.9667 - val_loss: 0.5985 - val_accuracy: 0.9667 - lr: 1.4996e-05\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 47s 11s/step - loss: 0.5824 - accuracy: 0.9500 - val_loss: 0.6700 - val_accuracy: 0.8667 - lr: 1.3569e-05\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 50s 12s/step - loss: 0.5673 - accuracy: 0.9500 - val_loss: 0.6159 - val_accuracy: 0.9333 - lr: 1.2277e-05\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.5761 - accuracy: 0.9417 - val_loss: 0.6351 - val_accuracy: 0.9333 - lr: 1.1109e-05\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.6135 - accuracy: 0.9583 - val_loss: 0.5796 - val_accuracy: 0.9667 - lr: 1.0052e-05\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.5865 - accuracy: 0.9417 - val_loss: 0.5601 - val_accuracy: 1.0000 - lr: 9.0953e-06\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.5828 - accuracy: 0.9333 - val_loss: 0.6437 - val_accuracy: 0.9667 - lr: 8.2298e-06\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5570 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5569945573806763, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save(\"/content/CNN.h5\")"
      ],
      "metadata": {
        "id": "oDnpLuKV6SPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set()\n",
        "\n",
        "def plot_training_history(history):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.lineplot(x=range(len(history.history['accuracy'])), y=history.history['accuracy'], label='Training Accuracy')\n",
        "    sns.lineplot(x=range(len(history.history['val_accuracy'])), y=history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.lineplot(x=range(len(history.history['loss'])), y=history.history['loss'], label='Training Loss')\n",
        "    sns.lineplot(x=range(len(history.history['val_loss'])), y=history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Yy1YUviS6TlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "J1tDIFH_6Xm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO NEXT:\n",
        "1. how to use the saved model to predict new images\n",
        "2. create doc for the notebook"
      ],
      "metadata": {
        "id": "ozSduuJ86dl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CNN for Pixel segmentation**"
      ],
      "metadata": {
        "id": "lEk3k9CQlHep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Load and preprocess an image\n",
        "def load_and_preprocess_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=1)\n",
        "    image = tf.image.resize(image, (256, 256))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "# Load and preprocess a mask\n",
        "def load_and_preprocess_mask(mask_path):\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    mask = tf.image.resize(mask, (256, 256))\n",
        "    mask = tf.cast(mask, tf.float32) / 255.0\n",
        "    return mask\n",
        "\n",
        "# Load the dataset\n",
        "def load_dataset(image_folder, mask_folder):\n",
        "    image_paths = glob.glob(os.path.join(image_folder, '*.JPG'))\n",
        "    mask_paths = glob.glob(os.path.join(mask_folder, '*.JPG'))\n",
        "\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        mask_path = os.path.join(mask_folder, os.path.basename(image_path))\n",
        "\n",
        "        image = load_and_preprocess_image(image_path)\n",
        "        mask = load_and_preprocess_mask(mask_path)\n",
        "\n",
        "        X_train.append(image)\n",
        "        y_train.append(mask)\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "\n",
        "    return X_train, y_train\n",
        "\n",
        "# U-Net model\n",
        "def unet_model(input_shape):\n",
        "    inputs = tf.keras.layers.Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Middle\n",
        "    conv4 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "\n",
        "    # Decoder\n",
        "    up5 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv4)\n",
        "    up5 = tf.keras.layers.Conv2D(256, 2, activation='relu', padding='same')(up5)\n",
        "    merge5 = tf.keras.layers.concatenate([conv3, up5], axis=3)\n",
        "    conv5 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(merge5)\n",
        "    conv5 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv5)\n",
        "    up6 = tf.keras.layers.Conv2D(128, 2, activation='relu', padding='same')(up6)\n",
        "    merge6 = tf.keras.layers.concatenate([conv2, up6], axis=3)\n",
        "    conv6 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(merge6)\n",
        "    conv6 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = tf.keras.layers.UpSampling2D(size=(2, 2))(conv6)\n",
        "    up7 = tf.keras.layers.Conv2D(64, 2, activation='relu', padding='same')(up7)\n",
        "    merge7 = tf.keras.layers.concatenate([conv1, up7], axis=3)\n",
        "    conv7 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(merge7)\n",
        "    conv7 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    # Output\n",
        "    output = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(conv7)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define input shape (256x256 with 1 channel, as it's grayscale)\n",
        "input_shape = (256, 256, 1)\n",
        "\n",
        "# Create the U-Net model\n",
        "model = unet_model(input_shape)\n",
        "\n",
        "# Compile the model with an appropriate loss function and optimizer\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'], run_eagerly=True)\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_image_folder = '/content/train_images'\n",
        "train_mask_folder = '/content/mask_images'\n",
        "X_train, y_train = load_dataset(train_image_folder, train_mask_folder)\n",
        "\n",
        "# Train the model using the dataset\n",
        "model.fit(X_train, y_train, batch_size=16, epochs=10)\n",
        "\n",
        "# After training, you can use the model for inference\n",
        "\n",
        "# Example: Performing inference on a test image\n",
        "test_image_path = '/content/test_images/144.JPG'\n",
        "test_image = load_and_preprocess_image(test_image_path)\n",
        "predicted_mask = model.predict(np.expand_dims(test_image, axis=0))\n",
        "\n",
        "# Display the results\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(np.squeeze(test_image), cmap='gray')\n",
        "plt.title('Test Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(np.squeeze(predicted_mask), cmap='gray')\n",
        "plt.title('Predicted Mask')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YFvVN0eYlNAR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}